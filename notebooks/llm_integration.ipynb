{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7931d65",
   "metadata": {},
   "source": [
    "## LLM Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940748c4",
   "metadata": {},
   "source": [
    "Once all the steps were developed:\n",
    "\n",
    "- Embedding Service\n",
    "- Ingestion Pipeline\n",
    "- Context retrieval\n",
    "\n",
    "Now its time to create the last part of the RAG-LLM technique. Send the context and the user's query to the LLM in order to the LLM to generate an answer.\n",
    "\n",
    "This time, I'll be using ChatGPT LLM's, but also can work with Google LLM and others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cde1008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from rag_llm_energy_expert.credentials import get_qdrant_config, get_llm_config\n",
    "from rag_llm_energy_expert.search.searchers import semantic_search\n",
    "from rag_llm_energy_expert.llm.chat import create_chat_session, generate_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea5ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_config=get_qdrant_config()\n",
    "llm_config=get_llm_config()\n",
    "collection_name = qdrant_config.COLLECTION_NAME + qdrant_config.COLLECTION_VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f8a07d",
   "metadata": {},
   "source": [
    "## Connecting the GENAI client\n",
    "\n",
    "code from: https://ai.google.dev/gemini-api/docs/text-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aeb4c12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = genai.Client(api_key=llm_config.API_KEY.get_secret_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f1fc1",
   "metadata": {},
   "source": [
    "Generating multi-turn conversations\n",
    "\n",
    "The chat format enables users to step incrementally toward answers and to get help with multipart problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51747ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new chat session\n",
    "chat = llm_client.chats.create(model=llm_config.MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4adb3603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay! That's great. How can I help you today? Are you looking for information about something specific, or just looking to chat? Tell me what's on your mind.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = chat.send_message(\"Hi, im 25 years old\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa9ae16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Since you are 25 years old and 5 years older than your sister, she is 25 - 5 = 20 years old.\\n\\nSo, your sister is **20 years old**.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message(\"If I am 5 years older than my sister. How old is she?\")\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c284c433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role - user: Hi, im 25 years old\n",
      "role - model: Okay! That's great. How can I help you today? Are you looking for information about something specific, or just looking to chat? Tell me what's on your mind.\n",
      "\n",
      "role - user: If I am 5 years older than my sister. How old is she?\n",
      "role - model: Since you are 25 years old and 5 years older than your sister, she is 25 - 5 = 20 years old.\n",
      "\n",
      "So, your sister is **20 years old**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in chat.get_history():\n",
    "    print(f'role - {message.role}',end=\": \")\n",
    "    print(message.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113b287",
   "metadata": {},
   "source": [
    "### Configuring parameters\n",
    "\n",
    "Every prompt sent to the model includes parameters that control how the model generates responses. You can configure these parameters, por let the model use the default options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00538a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new chat session\n",
    "chat2 = llm_client.chats.create(\n",
    "    model=llm_config.MODEL,\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=500,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a742326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's how to solve the problem:\n",
      "\n",
      "*   **Cost of apples:** 5 apples * $1/apple = $5\n",
      "*   **Cost of pears:** $10 (total) - $5 (apples) = $5\n",
      "*   **Cost per pear:** $5 / 2 pears = $2.50/pear\n",
      "\n",
      "**Answer:** The pears cost $2.50 each.\n"
     ]
    }
   ],
   "source": [
    "responses = chat2.send_message(\n",
    "    message = \"Hi, If I have 5 apples, and 2 pears, and for all of them I paid 10 USD, if the apples costs 1 USD, how much are the pears?\"\n",
    ")\n",
    "print(responses.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060a96c8",
   "metadata": {},
   "source": [
    "More model parameters can be found [here](https://ai.google.dev/gemini-api/docs/text-generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4116e76",
   "metadata": {},
   "source": [
    "### System Instructions\n",
    "\n",
    "System instructions let you steer the behaviour of a model baesd on you specific use case. When you provide system instructions, you give the model additional context to help it understand the task and generate more customized responses. The model should adhere to the system instructions over the full iteraction with the user, enabling you to specify product-level behaviour separete from the prompts provided by end users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2641ebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new chat session\n",
    "chat3 = llm_client.chats.create(\n",
    "    model=llm_config.MODEL,\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=500,\n",
    "        temperature=0.1,\n",
    "        system_instruction=\"You are a Mexican energy expert that solves doubts of clients. You must be as direct as possible. Your responses\" \\\n",
    "        \"shall not be longer than 2 paragraphs (5 lines each).\" \\\n",
    "        \"The responses shall be based on the context provided. If you don't know the answer, tell that you don't know.\" \\\n",
    "        \"Answer the user's questions in the same language as they're asked.\"\n",
    "    )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc09f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"En el nuevo modelo, cómo se considera a Pemex?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81305df",
   "metadata": {},
   "source": [
    "Semantic Search of the available info in the vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5555a84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-22 10:42:53.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mPreprocessing query...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:53.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mGenerating embeddings...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:55.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mEmbeddings generated successfully\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:55.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mPreparing embeddings for vector search\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:55.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mQuery preprocessed successfully\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:56.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query_results\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mProcessing query results...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:56.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query_results\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mQuery results processed\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Pemex y la CFE se mantienen como empresas 100% mexicanas y 100% del Estado, cuya organización, administración, organización y estructura corporativa serán acordes con las mejores prácticas internacionales.  \n",
      "**Legislación Secundaria**  \n",
      "- Pemex y CFE contarán con un régimen presupuestario especial y exclusivo que les otorga autonomía presupuestaria y las sujeta sólo al balance financiero y al techo de servicios personales.  \n",
      "- Para el manejo de su deuda, Pemex y CFE se regirán por lo dispuesto en un artículo especial de la Ley General de Deuda Pública. Ambas empresas podrán realizar negociaciones, así\n",
      "como contratar los financiamientos externos e internos que requieran, para lo que deberán\n",
      "coordinarse con la SHCP, sin requerir de su autorización.  \n",
      "- El Gobierno de la República dejará de ser el “administrador principal” de los órganos de gobierno de las Empresas Productivas del Estado para asumir el rol de propietario.\n",
      "\n",
      "- Toda la información geológica del país será entregada a CNH, quien la administrará en el Centro Nacional de Información de Hidrocarburos. Pemex y las empresas productivas del Estado\n",
      "y los particulares podrán realizar estudios de reconocimiento o exploración superficial, previa\n",
      "autorización de CNH.  \n",
      "- La legislación secundaria contempla que Pemex o los particulares podrán proponer a la SENER áreas a licitar en el futuro, con base en la información obtenida. Las propuestas no otorgan derechos ni ventajas para la suscripción de un contrato.\n",
      "\n",
      "### Asignaciones  \n",
      "- Se otorgarán a Pemex en la Ronda Cero.  \n",
      "- Posteriormente, se otorgan de forma excepcional a Pemex y a otras  \n",
      "Empresas Productivas del Estado.  \n",
      "- Las asignaciones permiten la adjudicación directa a Pemex de proyectos estratégicos tales como yacimientos transfronterizos.  \n",
      "- Los asignatarios podrán registrar el beneficio económico esperado  \n",
      "para efectos financieros y contables.\n",
      "\n",
      "### 19  \n",
      "-----  \n",
      "**Características del nuevo modelo**  \n",
      "- En el Artículo 25 Constitucional se plasma el principio de sustentabilidad como uno de los criterios para el desarrollo de los proyectos de infraestructura energética.  \n",
      "- El Ejecutivo Federal deberá incluir en el Programa Nacional para el Aprovechamiento Sustentable de la Energía los pasos a seguir, así como las condiciones de operación y financiamiento\n",
      "para promover el uso de tecnologías y combustibles más limpios.  \n",
      "- En el sector eléctrico se establecieron obligaciones para el uso de energías limpias y la reducción de emisiones contaminantes.  \n",
      "- Se crea la Agencia Nacional de Seguridad Industrial y Protección al Medio Ambiente del Sector Hidrocarburos. Ésta regulará la seguridad industrial para minimizar el riesgo de accidentes\n",
      "en instalaciones o afectaciones al medio ambiente causadas por la actividad petrolera.  \n",
      "**Legislación Secundaria**  \n",
      "- La Agencia Nacional de Seguridad Industrial y Protección al Medio Ambiente del Sector Hidrocarburos será un órgano desconcentrado de la Secretaría de Medio Ambiente y Recursos\n",
      "Naturales (SEMARNAT), especializado técnicamente y que contará con autonomía de\n",
      "gestión.  \n",
      "- Se propone que dicha Agencia tenga las atribuciones de regular, supervisar y sancionar en\n",
      "\n",
      "## III. Fondo Mexicano del Petróleo para la Estabilización y el Desarrollo  \n",
      "Durante los últimos 30 años, la industria petrolera y sus ingresos han sido el pilar de las finanzas públicas y el motor de la actividad económica del país. Hoy, el principal reto a las finanzas\n",
      "públicas es revertir la caída en la producción de petróleo. Hasta ahora, los altos precios de dicho\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(semantic_search(\n",
    "    query=query,\n",
    "    embedding_model_name=None,\n",
    "    chunk_overlap=0,\n",
    "    documents_limit=5,\n",
    "    collection_name=collection_name\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "093d3dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-22 10:42:56.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mPreprocessing query...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:56.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mGenerating embeddings...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:57.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mEmbeddings generated successfully\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:57.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mPreparing embeddings for vector search\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:57.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mQuery preprocessed successfully\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:57.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query_results\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mProcessing query results...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:57.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query_results\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mQuery results processed\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! Sí, Pemex tiene la posibilidad de migrar a la nueva modalidad de contratación. Esto le permitirá poner en producción yacimientos de hidrocarburos que actualmente no se explotan por falta de inversión, capacidad de ejecución y tecnología.\n"
     ]
    }
   ],
   "source": [
    "question = \"PEMEX podrá migrar a la nueva modalidad de contratación\"\n",
    "\n",
    "response = chat3.send_message(message=question,\n",
    "                              config = types.GenerateContentConfig(\n",
    "                                  temperature=0.5,\n",
    "                                  system_instruction=\"You are a Mexican energy expert that solves doubts of clients. Your responses\" \\\n",
    "        \"shall not be longer than 2 paragraphs (5 lines each).\" \\\n",
    "        \"The responses shall be based on the context provided. If you don't know the answer, tell that you don't know.\" \\\n",
    "        \"Answer the user's questions in the same language as they're asked. Try to generate friendly answers\"\\\n",
    "        f\"\"\"Context: {semantic_search(query=question,\n",
    "                                    embedding_model_name=None,\n",
    "                                    chunk_overlap=0,\n",
    "                                    collection_name = collection_name,\n",
    "                                    documents_limit = 5\n",
    "                                    )}\"\"\"\n",
    "                              ))\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0704abb",
   "metadata": {},
   "source": [
    "## Using the functions generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf887175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-22 10:42:58.933\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.llm.chat\u001b[0m:\u001b[36mcreate_chat_session\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mCreating a new chat session...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:58.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.llm.chat\u001b[0m:\u001b[36mcreate_chat_session\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mChat session created successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chat = create_chat_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "729a23cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-22 10:42:58.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.llm.chat\u001b[0m:\u001b[36mgenerate_response\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mGenerating response...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:58.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.llm.chat\u001b[0m:\u001b[36mgenerate_response\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mRetrieving context...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:58.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m37\u001b[0m - \u001b[1mPreprocessing query...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:42:58.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mGenerating embeddings...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:43:00.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mEmbeddings generated successfully\u001b[0m\n",
      "\u001b[32m2025-04-22 10:43:00.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m95\u001b[0m - \u001b[1mPreparing embeddings for vector search\u001b[0m\n",
      "\u001b[32m2025-04-22 10:43:00.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mQuery preprocessed successfully\u001b[0m\n",
      "\u001b[32m2025-04-22 10:43:00.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query_results\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mProcessing query results...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:43:00.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.search.searchers_auxiliars\u001b[0m:\u001b[36mprocess_query_results\u001b[0m:\u001b[36m131\u001b[0m - \u001b[1mQuery results processed\u001b[0m\n",
      "\u001b[32m2025-04-22 10:43:00.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.llm.chat\u001b[0m:\u001b[36mgenerate_response\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mContext retrieved successfully.\u001b[0m\n",
      "\u001b[32m2025-04-22 10:43:00.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.llm.chat\u001b[0m:\u001b[36mgenerate_response\u001b[0m:\u001b[36m90\u001b[0m - \u001b[1mGenerating response...\u001b[0m\n",
      "\u001b[32m2025-04-22 10:43:01.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mrag_llm_energy_expert.llm.chat\u001b[0m:\u001b[36mgenerate_response\u001b[0m:\u001b[36m92\u001b[0m - \u001b[1mResponse generated successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sí, se establece la posibilidad de que la Nación otorgue asignaciones o contratos a Pemex, lo que le permitiría poner en producción yacimientos de hidrocarburos que actualmente están ociosos por falta de inversión, capacidad de ejecución y tecnología.\n"
     ]
    }
   ],
   "source": [
    "query=\"PEMEX podrá migrar a la nueva modalidad de contratación\"\n",
    "\n",
    "print(generate_response(prompt=query, chat_session=chat, temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1249a566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
